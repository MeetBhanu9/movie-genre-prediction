#!/usr/bin/env python
# coding: utf-8

# In[41]:


import pandas as pd
import numpy as np


# In[ ]:


#converting the txt file into csv and importing it


# In[42]:


train_data=pd.read_csv("train_data.txt", sep=':::',engine='python',names=['Movie_Name', 'Genre','Description'])
train_data.head(5)


# In[43]:


test_data=pd.read_csv("test_data.txt", sep=':::',engine='python',names=['Movie_Name','Description'])
test_data.head(5)


# In[ ]:


#data visualization 


# In[44]:


import matplotlib.pyplot as plt
import seaborn as sns


# In[45]:


plt.figure(figsize=(12,8))
number = train_data.Genre.value_counts()
sns.barplot(x=number.index, y=number)
plt.ylabel("Number of Movies")
plt.xlabel("Codes of Genre")
plt.show()


# In[ ]:


#Data preprocessing


# In[ ]:


#As we know there is no need of names of the movie because it doesn't matter for genre  


# In[46]:


train_data = train_data.drop("Movie_Name", axis='columns')
train_data.head()


# In[47]:


test_data = test_data.drop("Movie_Name", axis='columns')
test_data.head()


# In[48]:


train_data.Genre.value_counts()


# In[ ]:


#mapping of categorical value of Genre column


# In[49]:


print(pd.Categorical(train_data.Genre))


# In[50]:


print(pd.Categorical(train_data.Genre).codes)
train_data.Genre=pd.Categorical(train_data.Genre).codes
train_data
train_data.Genre.value_counts()


# In[ ]:


# Lemmetization, Tokenization and Stop_words of Description 


# In[51]:


import spacy
nlp = spacy.load('en_core_web_sm')


# In[52]:


def preprocess(desc):
 #removing stopwords and lemmetize the text
    doc=nlp(desc)
    filtered_tokens=[]
    for token in doc:
        if token.is_stop or token.is_punct:
            continue
        filtered_tokens.append(token.lemma_)    
    return " ".join(filtered_tokens)


# In[53]:


print(train_data.Description[1])


# In[54]:


print(preprocess(train_data.Description[1]))


# In[62]:


train_data["New_desc"]=train_data.Description.apply(preprocess)
train_data.head()


# In[ ]:





# In[63]:


test_data["New_desc"]=test_data.Description.apply(preprocess)
test_data.head()


# In[ ]:


# Dependent and Independent Variables


# In[ ]:





# In[70]:


Y=train_data.loc[:,"Genre"]
X=train_data.loc[:,"New_desc"]
X


# In[56]:


Y


# In[65]:


X_test=test_data.loc[:,"New_desc"]
X_test


# In[58]:


test_sol=pd.read_csv("test_data_solution.txt", sep=':::',engine='python',names=['Movie_Name', 'Genre','Description'])
test_sol.head(5)


# In[59]:


test_sol.Genre=pd.Categorical(train_data.Genre).codes
test_sol=test_sol.drop("Movie_Name", axis='columns')
test_sol


# In[60]:


Y_test=test_sol.loc[:,"Genre"]
Y_test


# In[66]:


from sklearn.naive_bayes import MultinomialNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report
from sklearn.feature_extraction.text import TfidfVectorizer


# In[69]:


Model1=Pipeline(
[
    ('vectorizer_tfidf',TfidfVectorizer()),
    ('Multi NB',MultinomialNB())
])
Model1.fit(X,Y)
Y_Pred=Model1.predict(X_test)
print(classification_report(Y_test,Y_Pred))


# In[68]:


Model2=Pipeline(
[
    ('vectorizer_tfidf',TfidfVectorizer()),
    ('KNN',KNeighborsClassifier())
])
Model2.fit(X,Y)
Y_Pred=Model2.predict(X_test)
print(classification_report(Y_test,Y_Pred))


# In[ ]:




